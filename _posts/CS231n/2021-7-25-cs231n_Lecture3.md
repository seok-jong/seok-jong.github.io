---

title: "[CS231n] Lecture 3"
categories:
  - AI
tags:
  - AI
  - CS231n
"toc": true
"toc_sticky": true

---



# [CS231n] Lecture 3 | Loss Functions and Optimization 



## 1. loss function 

- Define a loss function that quantifies our unhappiness with the scores across the training data 



지난 시간에 알아본 linear classifier에 의한 결과를 사림이 시각적으로 판단하기 보다는 어떠한 알고리즘을 만들고 그 알고리즘이 **w(가중치)**가 좋은지 나쁜지를 정량화 할 방법이 필요하다. 
w에 의하여 도출된 각각의 스코어를 확인하고 이러한 결과를 낸 w가 **얼마나 나쁜지**를 판단하는 것이 바로 **손실 함수**이다. 손실 함수를 이용하여 가장 좋은 w가 아닌 **가장 덜 나쁜 w**를 찾는다. 이러한 과정을 **최적화 과정**이라고 한다. 

손실 함수에 대해서 알아보기 위해 3개의 class 를 예로 들어본다. 

![Screenshot from 2021-07-25 13-19-49](https://user-images.githubusercontent.com/77032455/126887583-8f1cfbdb-ea96-4989-baf4-5fa95cd71fb7.png)

이미지를 참고하면 x는 우리가 모델에 입력한 이미지를 의미하고 y는 target(label)에 해당된다. 클래스 별로 나온 score들의 평균이 해당 class의 평균 loss가 된다. 

이제 구체적으로 Image Classification에 적합한 한 손실함수를 예로 들어본다. 

### 1) Multi-class SVM Loss

![Screenshot from 2021-07-25 13-21-34](https://user-images.githubusercontent.com/77032455/126887606-0e08ed34-c080-4096-9fb0-9e7dfa1acc0b.png)

**Multi-class SVM loss**(support vector machine)
multi-class SVM은 여러 클래스를 다루기 위한 이진 SVM의 일반화된 형태이다.

 multi-class SVM의 작동방식을 설명하자면 
먼저 해당 클래스의 score가 아닌 나머지 score의 값을 모두 합친다. 이그리고 올바른 카테고리의 스코어와 올바르지 않은 카테고리의 스코어를 비교한다.
만약 올바른 카테고리와 올바르지 않은 카테고리의 격차가 safety margin(이 예시에서는 1 ) 이상이라면 이 class에 대해서 해당 class의 점수가 다른 class의 점수보다 월등히 높다는 것을 의미하기 때문에 loss를 반환하지 않는다.(0 을 반환 ) 만약 올바르지 않은 class의 점수가 더 크다면 그 차이 만큼 loss를 반환하게 되고 이러한 loss를 class별로 모두 합친 값이 그 class의 최종 loss값이 된다. 이러한 과정을 수식화한 것이 위 이미지의 오른쪽 식이다.

이런 류의 손실 함수를 **hinge loss**라고 부른다. 
(그래프에서 s_yi는 실제 정답 카테고리의 score이다. )

 이러한 loss function의 계산을 해보면 다음과 같다. 

![Screenshot from 2021-07-25 13-22-09](https://user-images.githubusercontent.com/77032455/126887616-21601706-78fc-44a3-b650-cc7c7efa0f81.png)

이러한 방법으로 각각의 class에 적용하면 모든 class에 대한 loss값을 도출할 수 있다. 
그리고 각 class 별로 도출된 loss값의 평균이 이 모델의 w값을 평가하는(얼마나 좋지 않은 w값을 가지고 있는지) 정량적 지표가 된다. 

- **q-1) What happens to loss if car scores change a bit?**
  위 이미지의 예시를 들면, car class의 결과로 나온 score들은 정답 카테고리와 나머지 카테고리의 값이 safety margin보다 월등히 차이가 난다고 볼 수 있다. SVM의 계산 방식에 따르면 safety margin의 크기 만큼만 격차를 가지게 되면 loss를 0으로 반환하므로 score에 조금의 변화가 생긴다 해도 safety margin만 만족시킨다면 loss에는 변화가 없을 것 이다.
- **q-2) What is the min/max possible loss?**
  car의 경우와 같이 정답 class의 점수가 월등히 높다면 loss는 0으로 출력된다. 
  하지만 올바르지 않은 class의 점수가 정답 class의 점수보다 크다면 큰만큼 loss가 출력된다. 따라서 도출될 수 있는 loss값은 무한대라고 볼 수 있다. 
- **q-3) At initialization W is small so all s=0. What is the loss?**
  SVM의 계산 방식에 따르면 정답 class와 틀린 class의 값이 모두 0이면 safety margin인 1만 출력하게 된다. 따라서 각 class의 loss값은 [클래스 수 - 1] 이다. 이러한 방식은 디버깅 과정에서 이용할 수 있는 방법이다. 
- **q-4) What if the sum was over all classes? ( including j = y_i)**
  정답 class의 경우 도출되는 loss 값이 1이므로 각 class 별로 loss값은 1 증가한다. 
  관례상 정답 class는 빼고 계산을 하며 최소 loss는 0이 된다. 
- **q-5) What if we used mean instead of sum?** 
  loss값은 이미 정량적으로 정해져 있고 mean을 사용한다면 단순히 값들을 리스케일링한다는 의미이기 때문에 아무런 변화도 없다.  (스코어값이 몇인지 상관 없기 때문) 
- **q-6) What if we used squre root?**
  trade off를 비 선형적인 방식으로 바꿔주기 때문에 결과는 달라질 것이다.
  예를 들어 정답이 아닌 class에 대한 score는 제곱의 값으로 나빠지게 되는 것이고 loss값을 받는 optimizer는 이를 제곱으로 받아들여 w에 더욱 큰 변화를 일으키게 된다. 
  이러한 점은 손실 함수를 이용해 어떤 에러에 대해 얼마나 신경쓰는지를 반영할 수 있는 방법이다.  



**Multiclass SVM Loss : Example code**

![Screenshot from 2021-07-25 13-22-46](https://user-images.githubusercontent.com/77032455/126887621-44ff6f0b-1090-4c24-87cc-01cec250cd0e.png)

위 코드는 SVM Loss를 코드로 나타낸 것이다. 주목해야 할 점은 정답 class의 score를 
margins[y] = 0 
이라는 코드를 통해 loss를 계산하는 과정에서 제외시켜주는 부분이다.  

**E.g.** 

- **Suppose that we found a W such that L = 0. Is this W unique?** 

  loss를 0으로 만드는 W는 유일하지 않다. 위에서 살펴 보았듯이 safety margin만 만족한다면 W의 값이 얼마가 되든 loss 값이 0이 되는 W는 여러개 존재한다. 

  가령 W가 loss를 0으로 만든다면 2W로 계산한다 해도 loss는 0이 된다. 



![Screenshot from 2021-07-25 13-23-16](https://user-images.githubusercontent.com/77032455/126887630-fad6a510-b872-46c8-a282-f9c4d77434f7.png)

하지만 우리가 위에서 살펴본 loss function에는 약간의 모순이 존재한다. 
loss function을 이용하여 우리는 loss값이 0인 지점에 도달해야 하는 것 같지만 그렇게 된다면 training data set에만 꼭 맞는 모델을 만들게 되어버린다. 
우리가 모델을 학습시킴으로써 얻고자하는 궁극적인 것은 새로운 데이터(test dataset)에 올바르게 작동하는 모델이다. 

위 이미지를 기반으로 예를 들면 
우리가 train dataset으로 이용하는 것이 파란 원 이라고하고 test dataset으로 이용하는 것을 초록색 네모라고 하면, 모델은 모든 파란 원에 가까워 지려 할 것이다. 하지만 모델은 궁극적으로 test dataset에 가까워 져야 하므로 파란 원에 가까워지는 것은 모델의 성능을 저하시킨다고 볼 수 있다. (과적합)

따라서 최종적으로 loss값을 도출 할 때, Regullarization을 더해서 도출하게 된다. 
data loss term은 train dataset에 fit하게 하고 Regularization은 train dataset에 덜 fit하게 만들어 줌으로써 모델을 단순하게 만들어 준다. 즉 train dataset에 대한 overfitting을 방지하는 역할을 한다. 

따라서 우리가 만든 모델은 위 이미지에서 초록색 선의 형태를 띄는 모델로 만들어 지게 된다.  

![Screenshot from 2021-07-25 13-23-49](https://user-images.githubusercontent.com/77032455/126887640-dea262d2-6202-4188-aeee-01588a0bb9c6.png)

Regularization에는 여러가지가 있다. 
가장 보편적인 것은 L2 Regularization( Weight decay )이다. 
Regularization은 모델이 training dataset에 overfitting 하지 못하도록 모델의 복잡도에 패널티를 부여하는 방법이다. 

그렇다면 L2 Regularization이 모델이 복잡한지 아닌지를 어떻게 측정할 수 있는지 의문이 생길 수 있다. 

![Screenshot from 2021-07-25 13-24-19](https://user-images.githubusercontent.com/77032455/126887653-37ffccbf-c87d-4200-82c4-0bcc830d0e4e.png)

위 이미지를 참고하면 W_1에는 하나의 값만 1이고 W_2의 값은 모두 0.25로 구성되어 있다. 
입력값인 X와 W의 내적을 통해 score를 계산하는데 위 예시에서는 모두 1의 값을 도출하는 것을 확인할 수 있다. 
여기서 L2의 경우 W_2를 더 선호하게 된다. W_2의 norm값이 더 작기 때문이다. 
따라서 L2는 분류기의 복잡도를 상대적으로 W1,W2중에 어떤 것이 더 coarse한지 측정한다.
 linear classification에서 W가 의미하는 것은 "얼마나 x가 output class와 닮았는지" 이다.
즉, L2가 원하는 것은 X의 모든 요소가 영향을 줬으면 하는 것이다. X의 특정한 요소가 영향을 미치기 보다 모든 X의 요소가 골고루 영향을 미치길 원한다면 L2를 통해 더욱 Robust한 모델을 만들 수 있는 것이다. 	

반면 L1은 정 반대이다. 
L1은 복잡도를 다르게 정의한다.  L1은 W에 존재하는 0의 갯수에 따라 모데르이 복잡도를 다룬다.  



### 2) Softmax Classifier ( Multinomial Logistic Regression )

SVM과 더불어 딥러닝에서 자주쓰는 또다른 손실 함수로는 Softamx Classifier가 있다. 
사실 딥러닝에서는 softmax를 더 자주쓴다고 한다.  

이전에 SVM을 알아 보았을 때, 우리는 score 값 자체에는 관심이 없었고 정답 class와 정답이 아닌 class의 차이에만 집중을 하여 loss값을 도출했다. 하지만 이번에 알아볼 softmax에서는 score 자체에 추가적인 의미를 부여한다.  softmax식을 이용하여 class 별 확률 분포를 계산하게 된다. 

![Screenshot from 2021-07-25 13-24-48](https://user-images.githubusercontent.com/77032455/126887658-8b868e77-9867-4287-a48a-fd20b2cea4c9.png)

softmax function에 대해서 간략히 설명을 하자면 자연상수( e )에 지수를 취함으로써 score가 양수가 되게 한다. 이후 그 값들의 합을 이용하여 정규화 시킨다. 결과적으로 우리는 확률 분포를 얻을 수 있고 이 값은 해당 클래스일 **확률**이 되는 것이다.
확률이기 때문에 모든 값은 0에서 1사이의 값이고 모든 class의 값들의 합은 1이 될 것이다. 

  이 함수를 통해 도출 된 값을 - log 를 취해서 최종적인 loss값으로 반환하게된다.
loss = - log(정답클래스 확률)

참고.

![Screenshot from 2021-07-25 13-25-38](https://user-images.githubusercontent.com/77032455/126887668-735e898e-7c82-474b-a337-d7fc83878e1c.png)

여기서 log앞에 -를 붙이는 이유는 손실 함수 자체가 얼마나 좋은지가 아니라 얼마나 좋지 않은지를 측정하기 때문에 붙힌다. 

 정리하자면 스코어를 softmax함수에 넣어서 계산한 값에 -log 값을 취한다.  
도출된 값을 의미적으로 해석하면 해당 class의 score가 정규화 한 뒤의 값이 작으면 작을수록 -log값을 취했을 때의 값은 커지게 된다. 따라서 loss값으로 전달하는 값은 커지게 된다. 

이러한 계산 방식을 실제로 계산해 보자. 

![Screenshot from 2021-07-25 13-27-36](https://user-images.githubusercontent.com/77032455/126887715-cec6252b-e5f9-4d4a-9db5-3cad474c7a1c.png)

이미지에서 확인할 수 있듯이 도출된 score를 exponential에 취하고 정규화 한 뒤, -log를 취한다. 

**Question**

- **q-1) What is the min/max possible loss L_i?**
  최종적으로 도출되는 값의 최소값은 0이고 최대값은 무한대이다. 
  해당 class의 score를 정규화 한 뒤의 값이 1이면 (모델이 정확하게 판단한 경우) -log를 취하면 0이 된다. 하지만 그 와 반대라면 -log함수는 무한대로 발산하여 loss값은 무한대가 된다. **하지만 loss가 0이 되려면 해당 class의 score는 무한대에 가까운 값이여야 하고 다른 class의 score는 음의 무한대 값이여야 한다.** 따라서 loss가 0인 경우는 절대 없다.
- **q-2) Usually at initalization W is small so all s=0/ What is the loss?**
  정답은 log(C)이다. 왜냐하면 softmax 함수의 수식을 따라가 보면 분모의 지수함수를 취한 후 모두 더한 값은 C가 될 것이고 분자는 1이 된다. 따라서 결과값은 log(C)가 된다. 
  이 또한 좋은 디버깅 전략이 될 수 있다. 



**E.g**

![Screenshot from 2021-07-25 13-28-32](https://user-images.githubusercontent.com/77032455/126887730-aa6f993c-1b71-4baa-abf6-c74f8da75621.png)

위 두 Loss Function을 정리하자.

linear classification을 구성하는 방법은 동일하다. 다만, score에 대해서 얼마나 나쁜지를 해석하는 방식이 다르다. 

SVM - 정답 score와 정답이 아닌 score간의 margin에 집중 
Softmax - softmax를 통해 도출된 확률값의 -log값에 집중 

두 loss function의 차이에 대해서 이야기 해 보자면 
SVM은 일정 마진( safety margin)을 넘기만 하면 더 이상 성능 개선이 일어나지 않는다. 
하지만 softmax의 경우 정답 class의 경우 무한대로 보내려 하고 정답이 아닌 class의 경우 음의 무한대로 보내려 한다. 따라서 score값에 미세한 변동이 있다면 즉각적으로 반응하게 된다. 

실제 딥러닝에서 두 손실함수의 성능의 차이는 크지 않지만 두 방법의 차이를 이해하고 있는 것이 유용하다고 한다. 



![Screenshot from 2021-07-25 13-29-36](https://user-images.githubusercontent.com/77032455/126887763-3a110a9a-4adb-47fa-97fa-eff178b93e68.png)

**Recap** 

입력데이터인 x와 가중치인 W값을 복잡한 함수 f에 넣은 후 loss function을 통해 우리가 가지고 있는 W값이 얼마나 나쁜지를 측정하고 그 값에 W를 통해 Regularization을 더한다.



## 2. Optimization

- Come up with a way of efficiently finding the parameters that minimize the loss function

지금까지 덜 안좋은 W를 찾기 위한 loss값을 구하기 위한 방법들을 배웠다. 하지만 실제로 어떠한 방법으로 W를 업데이트 시키는지 아직 모른다. 
이제 W를 업데이트 시키는 Optimization(최적화)에 대해서 알아보자. 

loss 값을 줄이는 방법을 산에서 가장 낮은 지점에 가는 것으로 비유를 할 수 있다. 우리가 현재 위치하고 있는 높이가 현재의 loss값 이라고 할 수 있다. 우리는 iterative한 방법을 통해 현재위치에서 점차적으로 가장 낮은 지역으로 이동하는 방법을 이용해야 한다.

1. Random search
   ![Screenshot from 2021-07-25 13-30-29](https://user-images.githubusercontent.com/77032455/126887793-714cf813-5087-4147-8524-4025efa984d5.png)

   가장 단순한 방법으로 생각해 볼 수 있는 것은 임의의 w 값들을 정해 놓고 이 w값들 중 어떠한 값이 가장 좋은 성능을 내는가(가장 적은 loss값을 내는) 를 판단해 보면 된다. 
   하지만 이러한 방법은 성능이 좋지 못하다는 것을 쉽게 예측할 수 있다. 

2.  Follow the slope 
   ![Screenshot from 2021-07-25 13-31-30](https://user-images.githubusercontent.com/77032455/126887809-28c20954-9347-42dd-a189-9a83775bcc53.png)

   더 나은 전략으로 지역의 기하학적 특성을 이용하는 전략을 떠올릴 수 있다. 
   현재위치에서 경사가 가장 낮은 방향으로 나아가는 것과 같은 원리이다. 
   이러한 방법은 간단해 보이지만 실제로 성능이 좋다. 실제로 NN이나 Linear classifier를 훈련시킬때, 일반적으로 사용하는 방법이다. 
   위 이미지에서 볼 수 있듯이 이 방법을 사용하기 위해 우리는 미분을 사용하게 된다. 
   x값은 벡터이기 때문에 이러한 미분의 개념을 다변수로 확장시켜야 한다.(편미분) 
   다변수에서의 미분값은 gradient가 되고 x는 각각의 편미분값의 집합이 된다. 

   즉, 여러 w값들의 변화량을 고려해 봄으로써 loss를 최적화 시킬 수 있는 방향으로 나아갈 수 있다는 뜻이다. 

   ![Screenshot from 2021-07-25 13-33-01](https://user-images.githubusercontent.com/77032455/126887840-ba1931d4-4367-4426-90da-9db87edefc20.png)

   우리는 W에 의한 gradient를 계산해야 한다. 이미지의 왼쪽에 위치한 것이 W이고 오른쪽에 위치한 것이 dW, gradient이다. dW값은 W의 각 요소에 대한 방향으로 아주 작은 step(h)만큼 이동했을 때의 변화량을 의미하고 이러한 값들을 이용하여 loss값을 다시 계산함으로써 한 W에 의한 Loss값의 변화량을 살펴보게 된다. 이러한 방법을 이용하여 loss가 최소가 되는 방향으로 iterate하게 된다. 하지만 이러한 방법은 W의 요소가 많아진다면 계산 횟수가 굉장히 많아지게 된다. 따라서 NN에 적용할 수 없다. 따라서 우리는 이러한 방법을 minibatch를 구성하여 대표 표본에 적용하여 W를 최적화한다. 

   ![Screenshot from 2021-07-25 13-33-38](https://user-images.githubusercontent.com/77032455/126887857-054f9093-abbf-4dc7-a0cb-e136f44c8ced.png)

   위 이미지는 그라디언트를 이용하여 W를 최적화 하는 방법을 코드로써 구현한 것이다. 
   코드의 내용을 살펴보면 W의 그라디언트를 계산하고 그 값에 -step_size를 곱하여 기존의 W에 적용하는 것을 확인할 수 있다. - 를 붙여서 계산하는 이유는 변화량이 +인 경우 -방향으로 진행해야하고 변화량이 -인 경우에는 +방향으로 진행해야 하므로 부호가 반대가 되어야 하기 때문이다. 

   step_size는 hyper parameter이므로 설계자가 직접 설정해야 하며 매우 중요하다. 

    

# Inference 

https://www.youtube.com/watch?v=d14TUNcbn1k&list=PLC1qU-LWwrF64f4QKQT-Vg5Wr4qEE1Zxk&index=4

http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture3.pdf



